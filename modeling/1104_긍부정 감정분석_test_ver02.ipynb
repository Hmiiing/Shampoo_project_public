{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터는 테스트용으로 전에 세정력만 전처리한 데이터를 썼습니다. 샘플이니깐 원하는 데이터셋  가져다 쓰면 되요 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_excel('샴푸샴푸세정력.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>product</th>\n",
       "      <th>review</th>\n",
       "      <th>세정력</th>\n",
       "      <th>cleansing</th>\n",
       "      <th>세정gram</th>\n",
       "      <th>뽀득gram</th>\n",
       "      <th>세정pos</th>\n",
       "      <th>뽀득pos</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>허벌에센스 핑크로즈 샴푸 490ml</td>\n",
       "      <td>기존에 상품대비 가격이 부담이었는데 할인율이 높아져서 만족하면서 사용하고 있어요...</td>\n",
       "      <td>아주 만족해요</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>허벌에센스 핑크로즈 샴푸 490ml</td>\n",
       "      <td>뽀득뽀득해요 성분 좋다는 샴푸 쓰다가 거품도 너무 안나고 세정력이 떨어져서 바꿔봤는...</td>\n",
       "      <td>보통이에요</td>\n",
       "      <td>1</td>\n",
       "      <td>['세정력이', '떨어져서', '바꿔봤는데', '뽀득뽀득', '씻겨서']</td>\n",
       "      <td>['뽀득뽀득해요', '성분', '좋다는', '샴푸', '쓰다가']</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>허벌에센스 핑크로즈 샴푸 490ml</td>\n",
       "      <td>매번쓰던거입니다 거품도풍넝하고맘에아두듭니다</td>\n",
       "      <td>아주 만족해요</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>허벌에센스 핑크로즈 샴푸 490ml</td>\n",
       "      <td>노란색 사용하다가 핑크색이 향이 더 좋을것 같아서 구매했어요</td>\n",
       "      <td>보통이에요</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>허벌에센스 핑크로즈 샴푸 490ml</td>\n",
       "      <td>비누와 같은 세정력 세장력은 좋은 것 같은데 샴푸 후 머릿결이 조금 뻣뻣한 느낌이 ...</td>\n",
       "      <td>보통이에요</td>\n",
       "      <td>1</td>\n",
       "      <td>['세정력', '세장력은', '좋은', '것', '같은데']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1              product  \\\n",
       "0           0             0  허벌에센스 핑크로즈 샴푸 490ml   \n",
       "1           1             1  허벌에센스 핑크로즈 샴푸 490ml   \n",
       "2           2             2  허벌에센스 핑크로즈 샴푸 490ml   \n",
       "3           3             3  허벌에센스 핑크로즈 샴푸 490ml   \n",
       "4           4             4  허벌에센스 핑크로즈 샴푸 490ml   \n",
       "\n",
       "                                              review      세정력  cleansing  \\\n",
       "0    기존에 상품대비 가격이 부담이었는데 할인율이 높아져서 만족하면서 사용하고 있어요...  아주 만족해요          0   \n",
       "1  뽀득뽀득해요 성분 좋다는 샴푸 쓰다가 거품도 너무 안나고 세정력이 떨어져서 바꿔봤는...    보통이에요          1   \n",
       "2                            매번쓰던거입니다 거품도풍넝하고맘에아두듭니다  아주 만족해요          0   \n",
       "3                  노란색 사용하다가 핑크색이 향이 더 좋을것 같아서 구매했어요    보통이에요          0   \n",
       "4  비누와 같은 세정력 세장력은 좋은 것 같은데 샴푸 후 머릿결이 조금 뻣뻣한 느낌이 ...    보통이에요          1   \n",
       "\n",
       "                                     세정gram  \\\n",
       "0                                       NaN   \n",
       "1  ['세정력이', '떨어져서', '바꿔봤는데', '뽀득뽀득', '씻겨서']   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4         ['세정력', '세장력은', '좋은', '것', '같은데']   \n",
       "\n",
       "                                 뽀득gram  세정pos  뽀득pos  pos  \n",
       "0                                   NaN      0      0    0  \n",
       "1  ['뽀득뽀득해요', '성분', '좋다는', '샴푸', '쓰다가']      0      1    1  \n",
       "2                                   NaN      0      0    0  \n",
       "3                                   NaN      0      0    0  \n",
       "4                                   NaN      1      0    1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data1.loc[:,['review','pos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19896, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>기존에 상품대비 가격이 부담이었는데 할인율이 높아져서 만족하면서 사용하고 있어요...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>뽀득뽀득해요 성분 좋다는 샴푸 쓰다가 거품도 너무 안나고 세정력이 떨어져서 바꿔봤는...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>매번쓰던거입니다 거품도풍넝하고맘에아두듭니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>노란색 사용하다가 핑크색이 향이 더 좋을것 같아서 구매했어요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>비누와 같은 세정력 세장력은 좋은 것 같은데 샴푸 후 머릿결이 조금 뻣뻣한 느낌이 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  pos\n",
       "0    기존에 상품대비 가격이 부담이었는데 할인율이 높아져서 만족하면서 사용하고 있어요...    0\n",
       "1  뽀득뽀득해요 성분 좋다는 샴푸 쓰다가 거품도 너무 안나고 세정력이 떨어져서 바꿔봤는...    1\n",
       "2                            매번쓰던거입니다 거품도풍넝하고맘에아두듭니다    0\n",
       "3                  노란색 사용하다가 핑크색이 향이 더 좋을것 같아서 구매했어요    0\n",
       "4  비누와 같은 세정력 세장력은 좋은 것 같은데 샴푸 후 머릿결이 조금 뻣뻣한 느낌이 ...    1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['pos'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.dropna(subset=['review'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13917, 1), (5965, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class_df = data2['pos']\n",
    "feature_df = data2.drop(['pos'], axis=1, inplace=False)\n",
    "\n",
    "#df_train, df_test = train_test_split(data2, test_size=0.3, random_state=0)\n",
    "X_train, X_test, y_train, y_test= train_test_split(feature_df, class_df, test_size=0.3, random_state=156)\n",
    "\n",
    "X_train.shape, X_test.shape\n",
    "#df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 머신러닝으로 감성분석 분류기 테스트_CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daehynk/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도는 0.9915, ROC-AUC는 0.9942\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# 스톱 워드는 English, filtering, ngram은 (1,2)로 설정해 CountVectorization수행. \n",
    "# LogisticRegression의 C는 10으로 설정. \n",
    "pipeline = Pipeline([\n",
    "    ('cnt_vect', CountVectorizer(ngram_range=(1,2) )),\n",
    "    ('lr_clf', LogisticRegression(C=10))])\n",
    "\n",
    "# Pipeline 객체를 이용하여 fit(), predict()로 학습/예측 수행. predict_proba()는 roc_auc때문에 수행.  \n",
    "pipeline.fit(X_train['review'], y_train)\n",
    "pred = pipeline.predict(X_test['review'])\n",
    "pred_probs = pipeline.predict_proba(X_test['review'])[:,1]\n",
    "\n",
    "print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test ,pred),\n",
    "                                         roc_auc_score(y_test, pred_probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daehynk/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도는 0.9920, ROC-AUC는 0.9929\n"
     ]
    }
   ],
   "source": [
    "# 스톱 워드는 english, filtering, ngram은 (1,2)로 설정해 TF-IDF 벡터화 수행. \n",
    "# LogisticRegression의 C는 10으로 설정. \n",
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(ngram_range=(1,2) )),\n",
    "    ('lr_clf', LogisticRegression(C=10))])\n",
    "\n",
    "pipeline.fit(X_train['review'], y_train)\n",
    "pred = pipeline.predict(X_test['review'])\n",
    "pred_probs = pipeline.predict_proba(X_test['review'])[:,1]\n",
    "\n",
    "print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test ,pred),\n",
    "                                         roc_auc_score(y_test, pred_probs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 딥러닝으로 감성 분석 코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['최고/NNG',\n",
      "  '입니다/VCP+EF',\n",
      "  '역시/MAJ',\n",
      "  '바티스트/NNG',\n",
      "  '만큼/JKB',\n",
      "  '가/JKS',\n",
      "  '성비/NNG',\n",
      "  '좋/VA',\n",
      "  '고/EC',\n",
      "  '좋/VA',\n",
      "  '은/ETM',\n",
      "  '드라이/NNG',\n",
      "  '샴푸/NNG',\n",
      "  '가/JKS',\n",
      "  '없/VA',\n",
      "  '는/ETM',\n",
      "  '것/NNB',\n",
      "  '같/VA',\n",
      "  '아요/EF',\n",
      "  '몇/MM',\n",
      "  '통/NNBC',\n",
      "  '째/XSN',\n",
      "  '구매/NNG',\n",
      "  '인지/VCP+EC',\n",
      "  '기억/NNG',\n",
      "  '도/JX',\n",
      "  '안/MAG',\n",
      "  '나/VV',\n",
      "  '네여/EF',\n",
      "  '머리/NNG',\n",
      "  '가/JKS',\n",
      "  '길/VA',\n",
      "  '어서/EC',\n",
      "  '매일/MAG',\n",
      "  '감기/NNG',\n",
      "  '가/JKS',\n",
      "  '든/VV+ETM',\n",
      "  '데/NNB',\n",
      "  '늘/MAG',\n",
      "  '쟁여/VV+EC',\n",
      "  '뒀/VX+EP',\n",
      "  '다가/EC',\n",
      "  '유용/NNG',\n",
      "  '하/XSV',\n",
      "  '게/EC',\n",
      "  '사용/NNG',\n",
      "  '합니다/XSV+EC'],\n",
      " 0)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "def tokenize(doc):\n",
    "    # norm은 정규화, stem은 근어로 표시하기를 나타냄\n",
    "    return ['/'.join(t) for t in mecab.pos(doc)]\n",
    "\n",
    "if os.path.isfile('train_docs.json'):\n",
    "    with open('train_docs.json') as f:\n",
    "        train_docs = json.load(f)\n",
    "    with open('test_docs.json') as f:\n",
    "        test_docs = json.load(f)\n",
    "else:\n",
    "    train_docs = [(tokenize(row),label ) for row,label in zip(X_train['review'],y_train)]\n",
    "    test_docs = [(tokenize(row),label ) for row,label in zip(X_test['review'],y_test)]\n",
    "    # JSON 파일로 저장\n",
    "    with open('train_docs.json', 'w', encoding=\"utf-8\") as make_file:\n",
    "        json.dump(train_docs, make_file, ensure_ascii=False, indent=\"\\t\")\n",
    "    with open('test_docs.json', 'w', encoding=\"utf-8\") as make_file:\n",
    "        json.dump(test_docs, make_file, ensure_ascii=False, indent=\"\\t\")\n",
    "\n",
    "# 예쁘게(?) 출력하기 위해서 pprint 라이브러리 사용\n",
    "pprint(train_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360867\n"
     ]
    }
   ],
   "source": [
    "tokens = [t for d in train_docs for t in d[0]]\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: 세정력>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "text = nltk.Text(tokens,name='세정력')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360867\n",
      "10299\n",
      "[('좋/VA', 12868),\n",
      " ('고/EC', 10269),\n",
      " ('이/JKS', 6630),\n",
      " ('도/JX', 6586),\n",
      " ('에/JKB', 5825),\n",
      " ('샴푸/NNG', 4438),\n",
      " ('는/ETM', 4308),\n",
      " ('어요/EF', 4255),\n",
      " ('아요/EF', 4125),\n",
      " ('가/JKS', 3970)]\n"
     ]
    }
   ],
   "source": [
    "# 전체 토큰의 개수\n",
    "print(len(text.tokens))\n",
    "\n",
    "# 중복을 제외한 토큰의 개수\n",
    "print(len(set(text.tokens)))            \n",
    "\n",
    "# 출현 빈도가 높은 상위 토큰 10개\n",
    "pprint(text.vocab().most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_words = [f[0] for f in text.vocab().most_common(10000)]\n",
    "\n",
    "def term_frequency(doc):\n",
    "    return [doc.count(word) for word in selected_words]\n",
    "\n",
    "train_x = [term_frequency(d) for d, _ in train_docs]\n",
    "test_x = [term_frequency(d) for d, _ in test_docs]\n",
    "train_y = [c for _, c in train_docs]\n",
    "test_y = [c for _, c in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = np.asarray(train_x).astype('float32')\n",
    "x_test = np.asarray(test_x).astype('float32')\n",
    "\n",
    "y_train = np.asarray(train_y).astype('float32')\n",
    "y_test = np.asarray(test_y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/daehynk/.local/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/daehynk/.local/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/10\n",
      "13917/13917 [==============================] - 2s 159us/sample - loss: 0.2976 - binary_accuracy: 0.9544\n",
      "Epoch 2/10\n",
      "13917/13917 [==============================] - 2s 123us/sample - loss: 0.1485 - binary_accuracy: 0.9846\n",
      "Epoch 3/10\n",
      "13917/13917 [==============================] - 2s 145us/sample - loss: 0.0724 - binary_accuracy: 0.9854\n",
      "Epoch 4/10\n",
      "13917/13917 [==============================] - 2s 134us/sample - loss: 0.0336 - binary_accuracy: 0.9898\n",
      "Epoch 5/10\n",
      "13917/13917 [==============================] - 2s 128us/sample - loss: 0.0176 - binary_accuracy: 0.9943\n",
      "Epoch 6/10\n",
      "13917/13917 [==============================] - 2s 126us/sample - loss: 0.0096 - binary_accuracy: 0.9972\n",
      "Epoch 7/10\n",
      "13917/13917 [==============================] - 2s 137us/sample - loss: 0.0057 - binary_accuracy: 0.9988\n",
      "Epoch 8/10\n",
      "13917/13917 [==============================] - 2s 178us/sample - loss: 0.0036 - binary_accuracy: 0.9993\n",
      "Epoch 9/10\n",
      "13917/13917 [==============================] - 2s 123us/sample - loss: 0.0021 - binary_accuracy: 0.9995\n",
      "Epoch 10/10\n",
      "13917/13917 [==============================] - 2s 136us/sample - loss: 0.0011 - binary_accuracy: 0.9996\n",
      "5965/5965 [==============================] - 1s 172us/sample - loss: 0.1303 - binary_accuracy: 0.9876\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "             loss=losses.binary_crossentropy,\n",
    "             metrics=[metrics.binary_accuracy])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13028755275269324, 0.9875943]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pos_neg(review):\n",
    "    token = tokenize(review)\n",
    "    tf = term_frequency(token)\n",
    "    data = np.expand_dims(np.asarray(tf).astype('float32'), axis=0)\n",
    "    score = float(model.predict(data))\n",
    "    if(score > 0.5):\n",
    "        print(\"[{}]는 {:.2f}% 확률로 긍정 리뷰이지 않을까 추측해봅니다.^^\\n\".format(review, score * 100))\n",
    "    else:\n",
    "        print(\"[{}]는 {:.2f}% 확률로 부정 리뷰이지 않을까 추측해봅니다.^^;\\n\".format(review, (1 - score) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[뽀득하고 세정이 잘 되는거 같아요.]는 80.92% 확률로 긍정 리뷰이지 않을까 추측해봅니다.^^\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_pos_neg(\"뽀득하고 세정이 잘 되는거 같아요.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[세정력 좋아요 향은 별로네요 두피가 시원해요]는 99.91% 확률로 부정 리뷰이지 않을까 추측해봅니다.^^;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_pos_neg(\"세정력 좋아요 향은 별로네요 두피가 시원해요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
